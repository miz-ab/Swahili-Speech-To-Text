{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Swahili_speech_recognition__.ipynb",
      "provenance": [],
      "mount_file_id": "17JXvg7cA4f5m9V2cCdOLFr85XTm6pRHJ",
      "authorship_tag": "ABX9TyMsYYS6Aw16mzYJWSMIrbbp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miz-ab/Swahili-Speech-To-Text/blob/dev/notebooks/Swahili_speech_recognition__.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyUueqDqS7KU"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83EuwlSdTiS0",
        "outputId": "46b5995f-083b-4036-ce78-ff07347a3290"
      },
      "source": [
        "rows = []\n",
        "p_dir = \"/content/drive/MyDrive/Week-4/speech_data/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/\"\n",
        "parent_dir = p_dir+\"SWH-05-20101106\"\n",
        "files = os.listdir(parent_dir)\n",
        "for f in files:\n",
        "    audio, fs = librosa.load(f\"{parent_dir}/{f}\")\n",
        "    filename = f.split('.')[0]\n",
        "    row = {'filename': filename, 'audio': audio}\n",
        "    rows.append(row)\n",
        "rows[:5]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'audio': array([0.02953335, 0.03225018, 0.02603412, ..., 0.09593043, 0.09478676,\n",
              "         0.05775513], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10'},\n",
              " {'audio': array([ 0.00471402,  0.00630584,  0.00576152, ...,  0.01627303,\n",
              "         -0.00729037, -0.01463527], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100'},\n",
              " {'audio': array([0.00886934, 0.00965257, 0.0063316 , ..., 0.22327209, 0.280469  ,\n",
              "         0.        ], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part101'},\n",
              " {'audio': array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n",
              "         -0.20379573, -0.11009098], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part102'},\n",
              " {'audio': array([0.01063866, 0.01384298, 0.01281647, ..., 0.0591335 , 0.05393954,\n",
              "         0.02577941], dtype=float32),\n",
              "  'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ULfMzGUcMC",
        "outputId": "0d56391c-3248-46e0-cbe3-09f60bda9e01"
      },
      "source": [
        "sample_audios = []\n",
        "for row in rows:\n",
        "    audio = row['audio']\n",
        "    sample_audios.append(audio)\n",
        "sample_audios[:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.02953335, 0.03225018, 0.02603412, ..., 0.09593043, 0.09478676,\n",
              "        0.05775513], dtype=float32),\n",
              " array([ 0.00471402,  0.00630584,  0.00576152, ...,  0.01627303,\n",
              "        -0.00729037, -0.01463527], dtype=float32),\n",
              " array([0.00886934, 0.00965257, 0.0063316 , ..., 0.22327209, 0.280469  ,\n",
              "        0.        ], dtype=float32),\n",
              " array([-0.01096754, -0.01230842, -0.01015999, ..., -0.21667908,\n",
              "        -0.20379573, -0.11009098], dtype=float32),\n",
              " array([0.01063866, 0.01384298, 0.01281647, ..., 0.0591335 , 0.05393954,\n",
              "        0.02577941], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MESf-LkUeon"
      },
      "source": [
        "meta_df = pd.read_csv('/content/drive/MyDrive/Swahili-Speech-To-Text-main___/metadata.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "Vujvz81gU6Gw",
        "outputId": "9edd6074-52a9-4bd4-e692-164ea4db5061"
      },
      "source": [
        "meta_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>transcription</th>\n",
              "      <th>filepath</th>\n",
              "      <th>sample_rate</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            filename  ... duration\n",
              "0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.14\n",
              "1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.10\n",
              "2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.65\n",
              "3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     3.90\n",
              "4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...  ...     2.94\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTLarZHwVGwK",
        "outputId": "eee7592e-39e2-4a50-bfee-7c95fbbf8024"
      },
      "source": [
        "meta_df['sample_rate'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000    10180\n",
              "Name: sample_rate, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzmYiDpbVK49",
        "outputId": "a48907dc-df44-41c0-b755-d6d2942e8584"
      },
      "source": [
        "meta_df.columns.to_list()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['filename', 'transcription', 'filepath', 'sample_rate', 'duration']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtZaEO_QVOZo",
        "outputId": "7e553860-f977-4757-8eb9-836f47357a44"
      },
      "source": [
        "txts = []\n",
        "for row in rows:\n",
        "    filename = row['filename']\n",
        "    filter = meta_df[meta_df['filename'] == filename]\n",
        "    txt = filter[['transcription']].values\n",
        "    txts.append(txt)\n",
        "\n",
        "txts[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([['rais wa tanzania jakaya mrisho kikwete']], dtype=object),\n",
              " array([['yanayo andaliwa nami pendo pondo idhaa ya kiswahili']],\n",
              "       dtype=object),\n",
              " array([['inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania']],\n",
              "       dtype=object),\n",
              " array([['juma hili bara la afrika limeshuhudia raia wa nchi za niger']],\n",
              "       dtype=object),\n",
              " array([['wakipiga kura ya maoni ilikufanya mabadiliko ya']], dtype=object)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGS-Ww2ZVSwM"
      },
      "source": [
        "txts = np.array(txts).reshape(-1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io-HYmvCVVQt",
        "outputId": "ef2bf3f8-931a-4885-c568-a040711f73c8"
      },
      "source": [
        "txts[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['rais wa tanzania jakaya mrisho kikwete',\n",
              "       'yanayo andaliwa nami pendo pondo idhaa ya kiswahili',\n",
              "       'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania',\n",
              "       'juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n",
              "       'wakipiga kura ya maoni ilikufanya mabadiliko ya'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx4Sz11OVZOf"
      },
      "source": [
        "clean_txts = []\n",
        "alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\n",
        "for txt in txts:\n",
        "    clean_txt = []\n",
        "    for c in txt:\n",
        "        if c not in alphabets and c != ' ':\n",
        "            continue\n",
        "        clean_txt.append(c)\n",
        "    clean_txt = ''.join(clean_txt)\n",
        "    clean_txts.append(clean_txt)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1fhpoJFVdRh",
        "outputId": "f1929f8b-99e5-438b-e93b-f138035f8b62"
      },
      "source": [
        "clean_txts[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rais wa tanzania jakaya mrisho kikwete',\n",
              " 'yanayo andaliwa nami pendo pondo idhaa ya kiswahili',\n",
              " 'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania',\n",
              " 'juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n",
              " 'wakipiga kura ya maoni ilikufanya mabadiliko ya']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0IsalIWVgyJ",
        "outputId": "658e544c-00a5-44eb-8716-8c411d03c92c"
      },
      "source": [
        "'' in clean_txts"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5tGh2tlUVik6",
        "outputId": "c41eac73-3f37-4e93-8970-f2c24dd3c9a1"
      },
      "source": [
        "df = pd.DataFrame(clean_txts)\n",
        "df.columns = ['texts']\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts\n",
              "0             rais wa tanzania jakaya mrisho kikwete\n",
              "1  yanayo andaliwa nami pendo pondo idhaa ya kisw...\n",
              "2  inayokutangazia moja kwa moja kutoka jijini da...\n",
              "3  juma hili bara la afrika limeshuhudia raia wa ...\n",
              "4    wakipiga kura ya maoni ilikufanya mabadiliko ya"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp8sdTNLVoG1",
        "outputId": "9fa635e5-ab2e-478f-8940-56876241a91a"
      },
      "source": [
        "idxs = df[df['texts'] == ''].index\n",
        "idxs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([19, 21, 56], dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZrf5m7kVrt-"
      },
      "source": [
        "del clean_txts[idxs[-1]]\n",
        "del clean_txts[idxs[-2]]\n",
        "del clean_txts[idxs[-3]]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EqoZUPuVvGm",
        "outputId": "88c5961e-cd9e-4025-8b71-8ed5d23459ab"
      },
      "source": [
        "'' in clean_txts"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok8wX8WkWGhS"
      },
      "source": [
        "del sample_audios[idxs[-1]]\n",
        "del sample_audios[idxs[-2]]\n",
        "del sample_audios[idxs[-3]]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXSJhUykWNEp"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGZEVN9DWGmk"
      },
      "source": [
        "def character_dict():\n",
        "    alphabet = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
        "    supported = alphabet.split()\n",
        "\n",
        "    char_map = {}\n",
        "    char_map[\"\"] = 0\n",
        "    char_map[\"<SPACE>\"] = 1\n",
        "    idx = 2\n",
        "    for c in supported:\n",
        "        char_map[c] = idx\n",
        "        idx += 1\n",
        "    index_map = {v: k for k, v in char_map.items()}\n",
        "    return char_map, index_map"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "panYqn_vWX7s"
      },
      "source": [
        "char_map, index_map = character_dict()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJCgVN06WgV2",
        "outputId": "7a3b352c-22e2-4f8c-eaa0-063f34483ca8"
      },
      "source": [
        "char_map"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '<SPACE>': 1,\n",
              " 'a': 2,\n",
              " 'b': 3,\n",
              " 'c': 4,\n",
              " 'd': 5,\n",
              " 'e': 6,\n",
              " 'f': 7,\n",
              " 'g': 8,\n",
              " 'h': 9,\n",
              " 'i': 10,\n",
              " 'j': 11,\n",
              " 'k': 12,\n",
              " 'l': 13,\n",
              " 'm': 14,\n",
              " 'n': 15,\n",
              " 'o': 16,\n",
              " 'p': 17,\n",
              " 'q': 18,\n",
              " 'r': 19,\n",
              " 's': 20,\n",
              " 't': 21,\n",
              " 'u': 22,\n",
              " 'v': 23,\n",
              " 'w': 24,\n",
              " 'x': 25,\n",
              " 'y': 26,\n",
              " 'z': 27}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNOFm8YWiGg"
      },
      "source": [
        "def text_to_int_sequence(text):\n",
        "    \"\"\" Convert text to an integer sequence \"\"\"\n",
        "    int_sequence = []\n",
        "    for c in text:\n",
        "        if c == ' ':\n",
        "            ch = char_map['<SPACE>']\n",
        "        elif c in alphabets:\n",
        "            ch = char_map[c]\n",
        "        else:\n",
        "            print(c)\n",
        "            print('character not found')\n",
        "            break\n",
        "        int_sequence.append(ch)\n",
        "    return np.array(int_sequence)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs65jLtUWnMZ"
      },
      "source": [
        "def int_sequence_to_text(int_sequence):\n",
        "    \"\"\" Convert an integer sequence to text \"\"\"\n",
        "    textch = []\n",
        "    for c in int_sequence:\n",
        "        ch = index_map[c]\n",
        "        textch.append(ch)\n",
        "    text = ''.join(textch)\n",
        "    text = text.replace('<SPACE>', ' ')\n",
        "    return text"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MktJECm-Wt6l"
      },
      "source": [
        "## Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em9xil43WyBi"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, audios, texts, batch_size=32):\n",
        "        self.audios = audios\n",
        "        self.texts = texts\n",
        "        self.batch_size = batch_size\n",
        "        self.steps = int(len(self.audios) // self.batch_size)\n",
        "        # self.index = 0\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    # def shuffle(self):\n",
        "    #     np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(self.steps*self.batch_size)\n",
        "        # np.random.shuffle(self.indexes)\n",
        "\n",
        "    def data_generation(self, batch_audios, batch_texts):\n",
        "\n",
        "        longest_audio = max([len(i) for i in batch_audios])\n",
        "        longest_txt = max([len(i) for i in batch_texts])\n",
        "\n",
        "        audios          = np.zeros([int(self.batch_size), longest_audio], dtype=\"float32\")\n",
        "        txts            = np.zeros([int(self.batch_size), longest_txt], dtype=\"int64\")\n",
        "        audio_length    = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
        "        txt_length      = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
        "\n",
        "        i = 0\n",
        "        for audio, txt in zip(batch_audios, batch_texts):\n",
        "\n",
        "            txt_len = len(txt)\n",
        "\n",
        "            txt = text_to_int_sequence(txt)\n",
        "            # print(txts.shape)\n",
        "            # print(np.array(txt).shape)\n",
        "            txts[i,: txt_len] = txt\n",
        "\n",
        "            audio_len = len(audio)\n",
        "\n",
        "            audios[i, :audio_len] = audio\n",
        "\n",
        "            audio_length[i] = audio_len\n",
        "            txt_length[i] = txt_len\n",
        "\n",
        "            i+=1          \n",
        "            \n",
        "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
        "        inputs = {\n",
        "                    'the_input':    tf.convert_to_tensor(audios), \n",
        "                    'the_labels':   tf.convert_to_tensor(txts), \n",
        "                    'input_length': tf.convert_to_tensor(audio_length), \n",
        "                    'label_length': tf.convert_to_tensor(txt_length)\n",
        "                }\n",
        "        return (inputs, outputs)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[int(index*self.batch_size):int((index+1)*self.batch_size)]\n",
        "    \n",
        "        batch_audios = [self.audios[int(i)] for i in indexes]\n",
        "        batch_texts = [self.texts[int(i)] for i in indexes]\n",
        "        \n",
        "        return  self.data_generation(batch_audios, batch_texts)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Ezo721W5Y0"
      },
      "source": [
        "dg = DataGenerator(sample_audios, clean_txts)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29iYAZutXIt4",
        "outputId": "890bceaa-e0b9-433a-d795-f756adcef439"
      },
      "source": [
        "len(dg)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bydWy7YCXLs3"
      },
      "source": [
        "batch1 = dg[0][0]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6dhA8RXN-H",
        "outputId": "6a39f8fd-8ece-4265-ec98-fda3930804e0"
      },
      "source": [
        "batch1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              " array([ 69237,  68355,  80483,  85995,  64827,  54023,  57771,  54684,\n",
              "         77837,  60417, 112455,  48069,  82688,  59094, 108266,  51597,\n",
              "         50054,  72545,  52700, 112455,  58653,  92831,  75411, 128993,\n",
              "         85995,  67694,  51818,  88202,  54023,  47628,  71883,  78057])>,\n",
              " 'label_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              " array([ 38,  51,  66,  59,  47,  30,  44,  36,  39,  38,  94,  38,  55,\n",
              "         35,  69,  34,  36,  42,  38,  61,  52,  59,  58, 102,  65,  52,\n",
              "         34,  55,  38,  25,  40,  60])>,\n",
              " 'the_input': <tf.Tensor: shape=(32, 128993), dtype=float32, numpy=\n",
              " array([[ 0.02953335,  0.03225018,  0.02603412, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.00471402,  0.00630584,  0.00576152, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.00886934,  0.00965257,  0.0063316 , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [-0.01929947, -0.0214183 , -0.01492864, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.00464254,  0.00063416, -0.00608059, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [-0.02031364, -0.02287264, -0.02081008, ...,  0.        ,\n",
              "          0.        ,  0.        ]], dtype=float32)>,\n",
              " 'the_labels': <tf.Tensor: shape=(32, 102), dtype=int64, numpy=\n",
              " array([[19,  2, 10, ...,  0,  0,  0],\n",
              "        [26,  2, 15, ...,  0,  0,  0],\n",
              "        [10, 15,  2, ...,  0,  0,  0],\n",
              "        ...,\n",
              "        [12, 22, 13, ...,  0,  0,  0],\n",
              "        [15,  2,  1, ...,  0,  0,  0],\n",
              "        [22, 13, 10, ...,  0,  0,  0]])>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWpC5sdlXXS7"
      },
      "source": [
        "## LogMelSpectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0B7n_7ZXZXp"
      },
      "source": [
        "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
        "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
        "\n",
        "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
        "                 f_min=0.0, f_max=None, **kwargs):\n",
        "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
        "        self.sample_rate = sample_rate\n",
        "        self.fft_size = fft_size\n",
        "        self.hop_size = hop_size\n",
        "        self.n_mels = n_mels\n",
        "        self.f_min = f_min\n",
        "        self.f_max = f_max if f_max else sample_rate / 2\n",
        "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
        "            num_mel_bins=self.n_mels,\n",
        "            num_spectrogram_bins=fft_size // 2 + 1,\n",
        "            sample_rate=self.sample_rate,\n",
        "            lower_edge_hertz=self.f_min,\n",
        "            upper_edge_hertz=self.f_max)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.non_trainable_weights.append(self.mel_filterbank)\n",
        "        super(LogMelSpectrogram, self).build(input_shape)\n",
        "\n",
        "    def call(self, waveforms):\n",
        "        \"\"\"Forward pass.\n",
        "        Parameters\n",
        "        ----------\n",
        "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
        "            A Batch of mono waveforms.\n",
        "        Returns\n",
        "        -------\n",
        "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
        "            The corresponding batch of log-mel-spectrograms\n",
        "        \"\"\"\n",
        "        def _tf_log10(x):\n",
        "            numerator = tf.math.log(x)\n",
        "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
        "            return numerator / denominator\n",
        "\n",
        "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
        "            \"\"\"\n",
        "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
        "            \"\"\"\n",
        "            ref_value = tf.reduce_max(magnitude)\n",
        "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
        "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
        "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
        "\n",
        "            return log_spec\n",
        "\n",
        "        spectrograms = tf.signal.stft(waveforms,\n",
        "                                      frame_length=self.fft_size,\n",
        "                                      frame_step=self.hop_size,\n",
        "                                      pad_end=False)\n",
        "\n",
        "        magnitude_spectrograms = tf.abs(spectrograms)\n",
        "\n",
        "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
        "                                     self.mel_filterbank)\n",
        "\n",
        "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
        "\n",
        "        # add channel dimension\n",
        "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
        "\n",
        "        return log_mel_spectrograms\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'fft_size': self.fft_size,\n",
        "            'hop_size': self.hop_size,\n",
        "            'n_mels': self.n_mels,\n",
        "            'sample_rate': self.sample_rate,\n",
        "            'f_min': self.f_min,\n",
        "            'f_max': self.f_max,\n",
        "        }\n",
        "        config.update(super(LogMelSpectrogram, self).get_config())\n",
        "\n",
        "        return config"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVNuBhwXXjyk"
      },
      "source": [
        "## CTC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNm-rzCqX3go"
      },
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2MxhB4SX8U8"
      },
      "source": [
        "def input_lengths_lambda_func(args):\n",
        "    input_length = args\n",
        "    return tf.cast(tf.math.floor(input_length/hop_size)-1, dtype=\"float32\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jzYXyV3YB_B"
      },
      "source": [
        "def add_ctc_loss(model_builder):\n",
        "    the_labels      = Input(name='the_labels',      shape=(None,), dtype='float32')\n",
        "    input_lengths   = Input(name='input_length',    shape=(1,), dtype='float32')\n",
        "    label_lengths   = Input(name='label_length',    shape=(1,), dtype='float32')\n",
        "\n",
        "    input_lengths2 = Lambda(input_lengths_lambda_func)(input_lengths)\n",
        "    if model_builder.output_length:\n",
        "         output_lengths  = Lambda(model_builder.output_length)(input_lengths2)\n",
        "    else:\n",
        "         output_lengths  = input_lengths2\n",
        "    \n",
        "    # CTC loss is implemented in a lambda layer\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([model_builder.output, the_labels, output_lengths, label_lengths])\n",
        "    model = Model( inputs=[model_builder.input, the_labels, input_lengths, label_lengths],  outputs=loss_out)\n",
        "    return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhrONKzmYGhY"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKxnAGWeYr7l"
      },
      "source": [
        "def preprocessin_model(sample_rate, fft_size, frame_step, n_mels, mfcc=False):\n",
        "\n",
        "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\n",
        "    featLayer = LogMelSpectrogram(\n",
        "        fft_size=fft_size,\n",
        "        hop_size=frame_step,\n",
        "        n_mels=n_mels,\n",
        "        \n",
        "        sample_rate=sample_rate,\n",
        "        f_min=0.0,\n",
        "        \n",
        "        f_max=int(sample_rate / 2)\n",
        "    )(input_data)\n",
        "    \n",
        "    x = BatchNormalization()(featLayer)\n",
        "    model = Model(inputs=input_data, outputs=x, name=\"preprocessin_model\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaSgydvfYwnd"
      },
      "source": [
        "def simple_rnn_model(input_dim, output_dim=224):\n",
        "\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    simp_rnn = GRU(output_dim, return_sequences=True,\n",
        "                   implementation=2, name='rnn')(input_data)\n",
        "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
        "    model = Model(inputs=input_data, outputs=y_pred, name=\"simple_rnn_model\")\n",
        "    model.output_length = lambda x: x\n",
        "    return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM2PQVaSY0z1"
      },
      "source": [
        "def train(model_builder, \n",
        "          data_gen,\n",
        "          epochs, \n",
        "          verbose=1,\n",
        "          optimizer=SGD(learning_rate=0.002, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
        "          ):    \n",
        "              \n",
        "    model = add_ctc_loss(model_builder)\n",
        "\n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
        "    print(model.summary())\n",
        "\n",
        "\n",
        "    hist = model.fit_generator(generator=data_gen,\n",
        "                               epochs=epochs,\n",
        "                               verbose=verbose, \n",
        "                               use_multiprocessing=False)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gguldrk_ciyx"
      },
      "source": [
        "## Model Trainig"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OOQUWGwcl2U"
      },
      "source": [
        "sample_rate = 16000\n",
        "fft_size = 1024\n",
        "frame_step = 512\n",
        "n_mels = 128\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "data_len = len(clean_txts)\n",
        "output_dim = len(char_map) + 2\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGvtmfgucrvU"
      },
      "source": [
        "dg = DataGenerator(sample_audios, clean_txts, batch_size)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvUVD-Y9ctlP",
        "outputId": "1695aed8-e716-4a4b-8137-44cb2b8a6eb9"
      },
      "source": [
        "preprocess_model = preprocessin_model(sample_rate, fft_size, frame_step, n_mels)\n",
        "preprocess_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"preprocessin_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "log_mel_spectrogram (LogMelS (None, None, 128, 1)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, None, 128, 1)      4         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 2\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FyQLOaJcxN-",
        "outputId": "214fcfcd-0530-4a64-880b-88dad2b6891c"
      },
      "source": [
        "speech_model = simple_rnn_model(n_mels, output_dim)\n",
        "speech_model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"simple_rnn_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "the_input (InputLayer)       [(None, None, 128)]       0         \n",
            "_________________________________________________________________\n",
            "rnn (GRU)                    (None, None, 30)          14400     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, None, 30)          0         \n",
            "=================================================================\n",
            "Total params: 14,400\n",
            "Trainable params: 14,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raZU4Q6Cc4r-"
      },
      "source": [
        "def build_model(output_dim, custom_model, preprocess_model, mfcc=False, calc=None):\n",
        "\n",
        "    input_audios = Input(name='the_input', shape=(None,))\n",
        "    pre = preprocess_model(input_audios)\n",
        "    pre = tf.squeeze(pre, [3])\n",
        "\n",
        "    y_pred = custom_model(pre)\n",
        "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
        "    model.output_length = calc\n",
        "\n",
        "    return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w_JzuhUc6Gl",
        "outputId": "304111a1-f8f5-4efe-aea8-f38e78c9cd60"
      },
      "source": [
        "model = build_model(output_dim, speech_model, preprocess_model)\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_builder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "the_input (InputLayer)       [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "preprocessin_model (Function (None, None, 128, 1)      4         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.squeeze (TFOpLa (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_model (Functional (None, None, 30)          14400     \n",
            "=================================================================\n",
            "Total params: 14,404\n",
            "Trainable params: 14,402\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gI7Pq3bdCtM"
      },
      "source": [
        "#!pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.tensorflow"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L_v7Y1zeDMy",
        "outputId": "7910c9f0-93ad-48b7-b88b-16f6d5515d1b"
      },
      "source": [
        "\n",
        "#mlflow.set_experiment('Speech model simple rnn')\n",
        "mlflow.tensorflow.autolog()\n",
        "hop_size = 512\n",
        "train(model, dg, epochs=10)\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "2021/08/11 17:11:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.7/dist-packages/mlflow/utils/autologging_utils/safety.py:216: UserWarning: Logging to MLflow failed: 'NoneType' object does not support item assignment\"\n",
            "2021/08/11 17:11:23 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: 'NoneType' object does not support item assignment\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessin_model (Functional) (None, None, 128, 1) 4           the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.squeeze (TFOpLambd (None, None, 128)    0           preprocessin_model[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "simple_rnn_model (Functional)   (None, None, 30)     14400       tf.compat.v1.squeeze[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1)            0           input_length[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           simple_rnn_model[0][0]           \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 lambda[0][0]                     \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 14,404\n",
            "Trainable params: 14,402\n",
            "Non-trainable params: 2\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 1s/step - loss: 319.9452\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 288.8101\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 266.3108\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 249.9663\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 239.4084\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 236.8742\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 236.2969\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 235.9609\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 235.9479\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 7s 1s/step - loss: 235.7417\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}